# nanoGPT
This is a decoder-only transformer model.



# Reference:
1.	Andrej Karpathy: Letâ€™s build GPT: from scratch, in code, spelled out. https://www.youtube.com/watch?v=kCc8FmEb1nY&t=878s
2.	Paper: Attention is all you need
https://arxiv.org/abs/1706.03762
3.	Jay Alammar: The Illustrated Transformer
 https://jalammar.github.io/illustrated-transformer/
4.	Harvardnlp: The Annotated Transformer
https://nlp.seas.harvard.edu/2018/04/03/attention.html
5.	Pytorch documentation: 
https://pytorch.org/docs/stable/index.html
